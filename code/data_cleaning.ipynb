{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d4c44c",
   "metadata": {},
   "source": [
    "# Data Cleaning and Merging\n",
    "\n",
    "In the following script, I am merging data from various sources to create one master data set that includes all the variables of interest to my analysis. Some key differences to note about Delhi is that the last Census of India occured in 2011, while multiple re-deliminations to municipal electoral ward boundaries were made in this decade, meaning boundary “vintages” do not line up cleanly across datasets, and I could not use the official Delhi GeoJSON because those were 2025/2026 boundaries. ([AP News][1])\n",
    "\n",
    "Therefore, to keep consistent geographic units, I took ward polygons from the community-compiled **DataMeet Municipal Spatial Data** repository, and as such should be taken with the errors that come with it. Note that these are **municipal wards (not census wards)**. In parallel, district boundaries were sourced from **HindustanTimesLabs** (Delhi district boundary GeoJSON), and each ward is assigned to a district using a centroid-based spatial join. ([GitHub][3])\n",
    "\n",
    "Because ward counts and boundaries changed over time, results should be interpreted as applying to the **ward geography used in the script**, rather than “today’s” wards. For reference, the State Election Commission documents that municipal elections were conducted for **272 wards** in 2017, and the 2022 delimitation process determined **250 wards** for the unified MCD. ([Delhi Government Security][4]) \n",
    "\n",
    "Additionally, another Delhi-specific complication is that the “Delhi local government” is not a single municipal body: the urban area includes separate jurisdictions under the **New Delhi Municipal Council (NDMC)** and the **Delhi Cantonment Board**, which are administratively distinct from the Municipal Corporation system that most ward datasets target. ([Delhi Government][5]) As a result, some wards, especially NDMC/Cantonment-related units in my final dataset, were not matched cleanly to ward-numbered population tables, and I added these manually from the census ward level data. ([Delhi Government][5])\n",
    "\n",
    "For public transport service, GTFS schedule tables are combined using standard GTFS identifiers (e.g., `stop_id`, `trip_id`, `route_id`), then bus stops are assigned to wards using a point-in-polygon spatial join. ([General Transit Feed Specification][6]) Bus service intensity is constructed as a standardized index of stop counts, route counts, and trip counts within each ward; this should be understood as a **constructed service index** rather than a directly published administrative statistic. Note that most GTFS based tables have a service calendar applied, but the data I downloaded for Delhi did not have times when service was not being offered, likely because the MCD does not presently have the infrastructure to keep track of this. Therefore, calendar counts based on `trip_id` represent a **proxy** for daily service rather than a fully calendar-filtered “trips per day” measure. ([General Transit Feed Specification][7])\n",
    "\n",
    "Several predictors are computed measures derived from spatial data rather than directly observed ward totals. Metro access is measured as distance (or inverse distance) from ward centroids to metro stations; if a complete station file is not available programmatically, results may reflect the station list used. Road density is estimated from **OpenStreetMap** road networks downloaded via **OSMnx**, which relies on OSM coverage and definitions (e.g., the “drive” network) and therefore can vary with map completeness. ([networkx.org][8])\n",
    "\n",
    "Comments and suggestions (especially for more efficient ways for finding Delhi data!) are always, always welcome. \n",
    "\n",
    "[1]: https://apnews.com/article/india-census-caste-politics-bihar-welfare-population-2a49a372c4f9bd79c4b0a11ed514c8a2 \"India will start its delayed census next year and will ask ...\"\n",
    "[2]: https://projects.datameet.org/Municipal_Spatial_Data \"Spatial Data of Municipalities (Maps)\"\n",
    "[3]: https://github.com/HindustanTimesLabs/shapefiles \"HindustanTimesLabs/shapefiles\"\n",
    "[4]: https://sec.delhi.gov.in/sec/general-election-272-wards-three-municipal-corporation-delhi-2017-respectively-supplysale \"General Election to 272 Wards of three Municipal ...\"\n",
    "[5]: https://des.delhi.gov.in/sites/default/files/DES/generic_multiple_files/report_on_lb_wise.pdf \"Report on Sixth Economic Census: Profile of Local Bodies, ...\"\n",
    "[6]: https://gtfs.org/documentation/schedule/reference \"General Transit Feed Specification Reference\"\n",
    "[7]: https://gtfs.org/getting-started/features/base \"Base\"\n",
    "[8]: https://networkx.org/documentation/stable/auto_examples/geospatial/plot_osmnx.html \"OpenStreetMap with OSMnx\"\n",
    "[9]: https://github.com/datameet/Municipal_Spatial_Data/issues/57 \"Delhi ward data is outdated · Issue #57 - GitHub\"\n",
    "[10]: https://github.com/HindustanTimesLabs/shapefiles/blob/master/city/delhi/district/delhi_1997-2012_district.json \"shapefiles/city/delhi/district/delhi_1997-2012_district.json ...\"\n",
    "[11]: https://sec.delhi.gov.in/sec/delimitation-order-2022 \"Delimitation Order 2022\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb01d2c",
   "metadata": {},
   "source": [
    "The following code merges the GTFS code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5ee566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 17)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "xlsx_path = Path(\"/Users/koniks/Desktop/Github Folder/public-program-evaluation/data/processed/Delhi_Bus_GTFS.xlsx\")\n",
    "out_dir = xlsx_path.parent\n",
    "out_xlsx = out_dir / \"gtfs_combined.xlsx\"\n",
    "out_csv  = out_dir / \"gtfs_combined.csv\"\n",
    "\n",
    "# ---------- LOAD ----------\n",
    "sheets = pd.read_excel(xlsx_path, sheet_name=None, dtype=str)\n",
    "sheets = {k.strip().lower(): v for k, v in sheets.items()}\n",
    "\n",
    "stops = sheets[\"stops\"]\n",
    "routes = sheets[\"routes\"]\n",
    "trips = sheets[\"trips\"]\n",
    "stop_times = sheets[\"stop_times\"]\n",
    "\n",
    "# ---------- COMBINE ----------\n",
    "combined = (\n",
    "    stop_times\n",
    "    .merge(trips, on=\"trip_id\", how=\"left\")\n",
    "    .merge(routes, on=\"route_id\", how=\"left\")\n",
    "    .merge(stops, on=\"stop_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "# ---------- SAVE ----------\n",
    "if len(combined) <= 1_048_576:\n",
    "    with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\") as writer:\n",
    "        combined.to_excel(writer, sheet_name=\"combined\", index=False)\n",
    "else:\n",
    "    combined.to_csv(out_csv, index=False)\n",
    "\n",
    "combined.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb63d128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DELHI WARD-LEVEL TRANSIT & ECONOMIC ANALYSIS - FIXED VERSION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "1. LOADING GTFS DATA\n",
      "======================================================================\n",
      "✓ Loaded 1,048,575 rows from combined GTFS\n",
      "✓ Unique stops with coordinates: 4,297\n",
      "\n",
      "======================================================================\n",
      "2. LOADING SPATIAL BOUNDARIES\n",
      "======================================================================\n",
      "Downloading Delhi ward boundaries...\n",
      "✓ Successfully loaded from: https://raw.githubusercontent.com/datameet/Municipal_Spatial_Data/master/Delhi/Delhi_Wards.geojson\n",
      "✓ Loaded 290 municipal wards\n",
      "✓ Created unique ward_key for 290 wards\n",
      "Downloading Delhi district boundaries...\n",
      "✓ Loaded from: https://raw.githubusercontent.com/datta07/INDIAN-SHAPEFILES/master/STATES/DELHI/DELHI_DISTRICTS.geojson\n",
      "✓ Loaded 11 districts\n",
      "✓ Ward-district mapping complete: 11 unique districts\n",
      "\n",
      "======================================================================\n",
      "3. CALCULATING BUS SERVICE METRICS\n",
      "======================================================================\n",
      "✓ Stops matched to wards: 4289 / 4297\n",
      "✓ Bus service metrics calculated for 255 wards\n",
      "\n",
      "======================================================================\n",
      "4. LOADING POPULATION DATA\n",
      "======================================================================\n",
      "✓ Loaded population data from local file: 289 rows\n",
      "  Columns: ['_id', 'Sl No', 'Ward', 'Population']\n",
      "✓ Prepared population for 217 unique ward_key values\n",
      "✓ Population density calculated\n",
      "\n",
      "======================================================================\n",
      "5. PROCESSING VEHICLE OWNERSHIP (RTO DATA) — NEAREST RTO ASSIGNMENT\n",
      "======================================================================\n",
      "✓ Loaded vehicle data: 20827 rows\n",
      "  Columns: ['Unnamed: 0', 'State', 'RTO', 'RTO Name', 'Year', 'Month', 'Metric', 'Name', 'Count']\n",
      "Detected columns:\n",
      "  rto_id_col  : RTO\n",
      "  rto_name_col: RTO Name\n",
      "  veh_type_col: Name\n",
      "  count_col   : Count\n",
      "✓ Retained 1,184 rows after vehicle-type filtering\n",
      "  Sample kept vehicle types: ['PLASTIC CARD FEE', 'SMART CARD FEE', 'TWO WHEELER(NT)', '-MOTOR CAR', 'HONDA CARS INDIA LTD', 'FOUR WHEELER (INVALID CARRIAGE)', 'DELETE SMART CARD FLAT FILE', '-MOPED']\n",
      "✓ Computed ownership score for 16 unique RTO offices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTO_LABEL</th>\n",
       "      <th>vehicle_ownership_rto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BURARI AUTO UNIT</td>\n",
       "      <td>1734817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MALL ROAD</td>\n",
       "      <td>770042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BURARI TAXI UNIT</td>\n",
       "      <td>561323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RAJPUR ROAD/VIU BURARI</td>\n",
       "      <td>164142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LONI ROAD</td>\n",
       "      <td>116398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WAZIRPUR</td>\n",
       "      <td>80675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOUTH DELHI</td>\n",
       "      <td>80103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWARKA</td>\n",
       "      <td>53393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SARAI KALE KHAN</td>\n",
       "      <td>42362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ROHINI</td>\n",
       "      <td>35604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RTO_LABEL  vehicle_ownership_rto\n",
       "0         BURARI AUTO UNIT                1734817\n",
       "6                MALL ROAD                 770042\n",
       "1         BURARI TAXI UNIT                 561323\n",
       "9   RAJPUR ROAD/VIU BURARI                 164142\n",
       "5                LONI ROAD                 116398\n",
       "15                WAZIRPUR                  80675\n",
       "12             SOUTH DELHI                  80103\n",
       "2                   DWARKA                  53393\n",
       "11         SARAI KALE KHAN                  42362\n",
       "10                  ROHINI                  35604"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using 20 RTO office locations (fixed list)\n",
      "✓ Fuzzy-matched 75.0% of RTO labels to the location list\n",
      "✓ Assigned nearest RTO ownership to 322 wards (should be all wards)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ward_key</th>\n",
       "      <th>vehicle_ownership</th>\n",
       "      <th>dist_to_rto_m</th>\n",
       "      <th>nearest_rto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CANT_1</td>\n",
       "      <td>29352</td>\n",
       "      <td>3233.226766</td>\n",
       "      <td>RAJA GARDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CANT_2</td>\n",
       "      <td>29352</td>\n",
       "      <td>4661.855167</td>\n",
       "      <td>RAJA GARDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CANT_4</td>\n",
       "      <td>33224</td>\n",
       "      <td>5551.821985</td>\n",
       "      <td>VASANT VIHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CANT_5</td>\n",
       "      <td>31757</td>\n",
       "      <td>7113.443040</td>\n",
       "      <td>JANAKPURI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CANT_6</td>\n",
       "      <td>31757</td>\n",
       "      <td>6295.381595</td>\n",
       "      <td>JANAKPURI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ward_key  vehicle_ownership  dist_to_rto_m   nearest_rto\n",
       "0   CANT_1              29352    3233.226766   RAJA GARDEN\n",
       "1   CANT_2              29352    4661.855167   RAJA GARDEN\n",
       "2   CANT_4              33224    5551.821985  VASANT VIHAR\n",
       "3   CANT_5              31757    7113.443040     JANAKPURI\n",
       "4   CANT_6              31757    6295.381595     JANAKPURI"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "6. PROCESSING NIGHTTIME LIGHTS (VIIRS 2012)\n",
      "======================================================================\n",
      "  Raster CRS: EPSG:4326\n",
      "  Raster shape: (33601, 86401)\n",
      "  Raster bounds: BoundingBox(left=-180.00208333335, bottom=-65.00208445335001, right=180.00208621335, top=75.00208333335)\n",
      "Extracting nighttime lights for 290 wards...\n",
      "✓ Nighttime lights extracted for 290 wards\n",
      "  Coverage: 290 wards with detected lights\n",
      "  Mean radiance: 50.04 nW/cm²/sr\n",
      "  Median radiance: 53.30 nW/cm²/sr\n",
      "  Max radiance: 95.98 nW/cm²/sr\n",
      "\n",
      "======================================================================\n",
      "7. CALCULATING INFRASTRUCTURE METRICS\n",
      "======================================================================\n",
      "✓ Metro access calculated for 290 wards\n",
      "  Mean distance: 0.51 km\n",
      "Downloading road network from OpenStreetMap...\n",
      "✓ Road density calculated for 290 wards\n",
      "\n",
      "======================================================================\n",
      "8. CREATING DISTRICT FIXED EFFECTS\n",
      "======================================================================\n",
      "✓ Created 11 district dummy variables\n",
      "\n",
      "======================================================================\n",
      "9. MERGING ALL DATA SOURCES — WITH NEAREST-RTO VEHICLE OWNERSHIP\n",
      "======================================================================\n",
      " Final dataset: 322 rows × 35 columns\n",
      "  Vehicle ownership coverage: 100.0%\n",
      "  (Optional) Nearest RTO label coverage: 100.0%\n",
      "\n",
      "======================================================================\n",
      "10. DATA QUALITY CHECKS\n",
      "======================================================================\n",
      "Missing value summary:\n",
      "Population             77\n",
      "population_density     77\n",
      "Stops_i                41\n",
      "Routes_i               41\n",
      "TripsPerDay_i          41\n",
      "zStops                 41\n",
      "zRoutes                41\n",
      "zTripsPerDay           41\n",
      "BusServiceIntensity    41\n",
      "dtype: int64\n",
      "  Ward keys unique: False\n",
      "  Bus service coverage: 87.3%\n",
      "  Population coverage: 76.1%\n",
      "  Vehicle ownership coverage: 100.0%\n",
      "  Nighttime lights coverage: 100.0%\n",
      "  Metro access coverage: 100.0%\n",
      "\n",
      "======================================================================\n",
      "11. SAVING OUTPUT\n",
      "======================================================================\n",
      "✓ Dataset saved: /Users/koniks/Desktop/Github Folder/public-program-evaluation/data/clean/analysis_dataset_ward_level.csv\n",
      "\n",
      "Final shape: (322, 35)\n",
      "\n",
      "======================================================================\n",
      "SUMMARY STATISTICS\n",
      "======================================================================\n",
      "\n",
      "BusServiceIntensity:\n",
      "  Mean: -0.03\n",
      "  Std: 0.93\n",
      "  Min: -0.88\n",
      "  Max: 4.77\n",
      "  Missing: 41 (12.7%)\n",
      "\n",
      "Population:\n",
      "  Mean: 50680.08\n",
      "  Std: 15454.02\n",
      "  Min: 5993.00\n",
      "  Max: 143324.00\n",
      "  Missing: 77 (23.9%)\n",
      "\n",
      "vehicle_ownership:\n",
      "  Mean: 89543.08\n",
      "  Std: 168123.86\n",
      "  Min: 18948.00\n",
      "  Max: 770042.00\n",
      "  Missing: 0 (0.0%)\n",
      "\n",
      "nighttime_lights:\n",
      "  Mean: 49.52\n",
      "  Std: 16.56\n",
      "  Min: 4.58\n",
      "  Max: 95.98\n",
      "  Missing: 0 (0.0%)\n",
      "\n",
      "metro_access_km:\n",
      "  Mean: 0.52\n",
      "  Std: 1.14\n",
      "  Min: 0.00\n",
      "  Max: 10.08\n",
      "  Missing: 0 (0.0%)\n",
      "\n",
      "population_density:\n",
      "  Mean: 36644.40\n",
      "  Std: 33045.64\n",
      "  Min: 438.93\n",
      "  Max: 275327.55\n",
      "  Missing: 77 (23.9%)\n",
      "\n",
      "======================================================================\n",
      "✓ ANALYSIS COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "First 5 rows:\n",
      "  ward_key             ward_name  Population  vehicle_ownership  \\\n",
      "0   CANT_1  DELHI CANTT CHARGE 1         NaN              29352   \n",
      "1   CANT_2  DELHI CANTT CHARGE 2         NaN              29352   \n",
      "2   CANT_4  DELHI CANTT CHARGE 4         NaN              33224   \n",
      "3   CANT_5  DELHI CANTT CHARGE 5         NaN              31757   \n",
      "4   CANT_6  DELHI CANTT CHARGE 6         NaN              31757   \n",
      "\n",
      "   nighttime_lights  BusServiceIntensity  \n",
      "0         34.159935            -0.741199  \n",
      "1         25.190216             0.017734  \n",
      "2         31.163273             0.113482  \n",
      "3         37.191505            -0.326508  \n",
      "4         43.255730             0.691470  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "import warnings\n",
    "import requests\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DELHI WARD-LEVEL TRANSIT & ECONOMIC ANALYSIS - FIXED VERSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "base_dir = Path(\"/Users/koniks/Desktop/Github Folder/public-program-evaluation/data\")\n",
    "gtfs_combined = base_dir / \"processed/gtfs_combined.xlsx\"\n",
    "vehicle_file = base_dir / \"raw/2021.csv\"\n",
    "pop_file = base_dir / \"raw/Census 2011 Ward-Level Population Data (OpenCity).csv\"\n",
    "output_file = base_dir / \"clean/analysis_dataset_ward_level.csv\"\n",
    "\n",
    "# ---------- LOAD GTFS DATA ----------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. LOADING GTFS DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "gtfs = pd.read_excel(gtfs_combined, sheet_name='combined', dtype=str)\n",
    "print(f\"✓ Loaded {len(gtfs):,} rows from combined GTFS\")\n",
    "\n",
    "stops = gtfs[['stop_id', 'stop_lat', 'stop_lon']].drop_duplicates()\n",
    "stops = stops.dropna(subset=['stop_lat', 'stop_lon'])\n",
    "stops['stop_lat'] = pd.to_numeric(stops['stop_lat'], errors='coerce')\n",
    "stops['stop_lon'] = pd.to_numeric(stops['stop_lon'], errors='coerce')\n",
    "stops = stops.dropna()\n",
    "print(f\"✓ Unique stops with coordinates: {len(stops):,}\")\n",
    "\n",
    "# ---------- LOAD SPATIAL BOUNDARIES ----------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. LOADING SPATIAL BOUNDARIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load wards\n",
    "ward_urls = [\n",
    "    \"https://raw.githubusercontent.com/datameet/Municipal_Spatial_Data/master/Delhi/Delhi_Wards.geojson\",\n",
    "    \"https://github.com/datameet/Municipal_Spatial_Data/raw/master/Delhi/Delhi_Wards.geojson\"\n",
    "]\n",
    "\n",
    "print(\"Downloading Delhi ward boundaries...\")\n",
    "wards = None\n",
    "for url in ward_urls:\n",
    "    try:\n",
    "        wards = gpd.read_file(url)\n",
    "        print(f\"✓ Successfully loaded from: {url}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "if wards is None:\n",
    "    raise Exception(\"Could not load ward boundaries\")\n",
    "\n",
    "print(f\"✓ Loaded {len(wards)} municipal wards\")\n",
    "\n",
    "# Create consistent ward keys\n",
    "wards['ward_id'] = wards['Ward_No'].astype(str).str.strip()\n",
    "wards['ward_name'] = wards['Ward_Name'].astype(str).str.strip()\n",
    "wards['ward_no_numeric'] = pd.to_numeric(wards['ward_id'], errors='coerce')\n",
    "\n",
    "# Create unique ward_key\n",
    "ward_counts = wards['ward_no_numeric'].value_counts()\n",
    "non_unique = ward_counts[ward_counts > 1].index\n",
    "wards['ward_key'] = wards.apply(\n",
    "    lambda x: x['ward_id'] if pd.isna(x['ward_no_numeric']) or x['ward_no_numeric'] in non_unique.values\n",
    "    else str(int(x['ward_no_numeric'])),\n",
    "    axis=1\n",
    ")\n",
    "print(f\"✓ Created unique ward_key for {len(wards)} wards\")\n",
    "\n",
    "# Load Delhi districts from GADM or datta07 repository\n",
    "print(\"Downloading Delhi district boundaries...\")\n",
    "district_urls = [\n",
    "    \"https://raw.githubusercontent.com/datta07/INDIAN-SHAPEFILES/master/STATES/DELHI/DELHI_DISTRICTS.geojson\",\n",
    "    \"https://github.com/datta07/INDIAN-SHAPEFILES/raw/master/STATES/DELHI/DELHI_DISTRICTS.geojson\"\n",
    "]\n",
    "\n",
    "districts = None\n",
    "for url in district_urls:\n",
    "    try:\n",
    "        districts = gpd.read_file(url)\n",
    "        print(f\"✓ Loaded from: {url}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "if districts is None:\n",
    "    print(\"⚠️  Could not load districts, creating from ward spatial join...\")\n",
    "    # Fallback: create districts by aggregating nearby wards\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    ward_centroids = wards.geometry.centroid\n",
    "    coords = np.array([[p.x, p.y] for p in ward_centroids])\n",
    "\n",
    "    kmeans = KMeans(n_clusters=11, random_state=42)\n",
    "    wards['district'] = kmeans.fit_predict(coords)\n",
    "    wards['district'] = 'District_' + wards['district'].astype(str)\n",
    "else:\n",
    "    # Identify district name column\n",
    "    dist_name_col = None\n",
    "    for col in ['DISTRICT', 'District', 'district', 'NAME', 'Name', 'name', 'DIST_NAME']:\n",
    "        if col in districts.columns:\n",
    "            dist_name_col = col\n",
    "            break\n",
    "\n",
    "    if dist_name_col is None:\n",
    "        dist_name_col = [c for c in districts.columns if c != 'geometry'][0]\n",
    "\n",
    "    districts['DISTRICT'] = districts[dist_name_col].astype(str).str.strip()\n",
    "    print(f\"✓ Loaded {len(districts)} districts\")\n",
    "\n",
    "    # Spatial join\n",
    "    wards_with_district = gpd.sjoin(wards, districts[['DISTRICT', 'geometry']],\n",
    "                                     how='left', predicate='intersects')\n",
    "    wards_with_district = wards_with_district.drop_duplicates(subset='ward_key')\n",
    "    wards_with_district['district'] = wards_with_district['DISTRICT'].fillna('Unknown')\n",
    "\n",
    "    # ✅ ONLY CHANGE: keep ward_no_numeric so later code (NTL seed) doesn't break\n",
    "    wards = wards_with_district[['ward_key', 'ward_id', 'ward_name', 'ward_no_numeric', 'district', 'geometry']]\n",
    "\n",
    "print(f\"✓ Ward-district mapping complete: {wards['district'].nunique()} unique districts\")\n",
    "\n",
    "# Calculate ward areas\n",
    "wards['ward_area_km2'] = wards.to_crs('EPSG:32643').geometry.area / 1e6\n",
    "\n",
    "# ---------- BUS SERVICE METRICS ----------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. CALCULATING BUS SERVICE METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "stops_gdf = gpd.GeoDataFrame(\n",
    "    stops,\n",
    "    geometry=[Point(xy) for xy in zip(stops['stop_lon'], stops['stop_lat'])],\n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "stops_with_ward = gpd.sjoin(stops_gdf, wards, how='left', predicate='within')\n",
    "matched = stops_with_ward['ward_key'].notna().sum()\n",
    "print(f\"✓ Stops matched to wards: {matched} / {len(stops)}\")\n",
    "\n",
    "service = gtfs.groupby('stop_id').agg({\n",
    "    'route_id': 'nunique',\n",
    "    'trip_id': 'count'\n",
    "}).reset_index()\n",
    "service.columns = ['stop_id', 'routes_per_stop', 'trips_per_stop']\n",
    "\n",
    "stops_with_service = stops_with_ward.merge(service, on='stop_id', how='left')\n",
    "stops_with_service['routes_per_stop'] = stops_with_service['routes_per_stop'].fillna(0)\n",
    "stops_with_service['trips_per_stop'] = stops_with_service['trips_per_stop'].fillna(0)\n",
    "\n",
    "ward_metrics = stops_with_service.groupby('ward_key').agg({\n",
    "    'stop_id': 'count',\n",
    "    'routes_per_stop': 'sum',\n",
    "    'trips_per_stop': 'sum'\n",
    "}).reset_index()\n",
    "ward_metrics.columns = ['ward_key', 'Stops_i', 'Routes_i', 'TripsPerDay_i']\n",
    "\n",
    "# Standardize\n",
    "from scipy.stats import zscore\n",
    "ward_metrics['zStops'] = zscore(ward_metrics['Stops_i'])\n",
    "ward_metrics['zRoutes'] = zscore(ward_metrics['Routes_i'])\n",
    "ward_metrics['zTripsPerDay'] = zscore(ward_metrics['TripsPerDay_i'])\n",
    "ward_metrics['BusServiceIntensity'] = (\n",
    "    ward_metrics['zStops'] + ward_metrics['zRoutes'] + ward_metrics['zTripsPerDay']\n",
    ") / 3\n",
    "\n",
    "print(f\"✓ Bus service metrics calculated for {len(ward_metrics)} wards\")\n",
    "\n",
    "# ---------- POPULATION DATA ----------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. LOADING POPULATION DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    population = pd.read_csv(pop_file)\n",
    "    print(f\"✓ Loaded population data from local file: {len(population)} rows\")\n",
    "    print(f\"  Columns: {population.columns.tolist()}\")\n",
    "\n",
    "    # robust column detection\n",
    "    cols_l = {c.lower().strip(): c for c in population.columns}\n",
    "    ward_col = cols_l.get(\"ward\") or cols_l.get(\"ward_no\") or cols_l.get(\"ward number\") or list(population.columns)[0]\n",
    "    pop_col = cols_l.get(\"population\") or cols_l.get(\"total population\") or cols_l.get(\"total\") or list(population.columns)[1]\n",
    "\n",
    "    # ward_key from ward label like \"DMC Ward No - 192\" OR plain numbers\n",
    "    population[\"ward_key\"] = (\n",
    "        population[ward_col]\n",
    "        .astype(str)\n",
    "        .str.extract(r\"(\\d+)\", expand=False)\n",
    "        .astype(\"Int64\")\n",
    "        .astype(str)\n",
    "    )\n",
    "\n",
    "    population[\"Population\"] = pd.to_numeric(population[pop_col], errors=\"coerce\")\n",
    "\n",
    "    # Aggregate duplicates to prevent row inflation during merges\n",
    "    population = (\n",
    "        population.dropna(subset=[\"ward_key\"])\n",
    "        .groupby(\"ward_key\", as_index=False)[\"Population\"].sum()\n",
    "    )\n",
    "\n",
    "    print(f\"✓ Prepared population for {len(population)} unique ward_key values\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Could not load local population data: {e}\")\n",
    "    population = pd.DataFrame({\"ward_key\": wards[\"ward_key\"], \"Population\": np.nan})\n",
    "\n",
    "# Calculate density\n",
    "ward_pop = wards[[\"ward_key\", \"ward_area_km2\"]].merge(population, on=\"ward_key\", how=\"left\")\n",
    "ward_pop[\"population_density\"] = ward_pop[\"Population\"] / ward_pop[\"ward_area_km2\"]\n",
    "print(\"✓ Population density calculated\")\n",
    "\n",
    "# ======================================================================\n",
    "# ---------- VEHICLE OWNERSHIP FROM RTO DATA (REWRITTEN: NEAREST-RTO) ----\n",
    "# ======================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. PROCESSING VEHICLE OWNERSHIP (RTO DATA) — NEAREST RTO ASSIGNMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ---- Load vehicle data ----\n",
    "vehicle_raw = pd.read_csv(vehicle_file)\n",
    "print(f\"✓ Loaded vehicle data: {len(vehicle_raw)} rows\")\n",
    "print(f\"  Columns: {vehicle_raw.columns.tolist()}\")\n",
    "\n",
    "# ---- Robust column detection ----\n",
    "def find_col(df, candidates):\n",
    "    cols_l = {c.lower().strip(): c for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        if cand.lower().strip() in cols_l:\n",
    "            return cols_l[cand.lower().strip()]\n",
    "    # contains fallback\n",
    "    for cand in candidates:\n",
    "        for c in df.columns:\n",
    "            if cand.lower() in c.lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "rto_id_col   = find_col(vehicle_raw, [\"rto\"])\n",
    "rto_name_col = find_col(vehicle_raw, [\"rto name\"])\n",
    "count_col    = find_col(vehicle_raw, [\"count\"])\n",
    "\n",
    "veh_type_col = find_col(vehicle_raw, [\"name\"])\n",
    "\n",
    "# Require minimal inputs\n",
    "if rto_id_col is None and rto_name_col is None:\n",
    "    raise ValueError(\"Could not find RTO identifier column in 2021.csv (expected something like 'RTO' or 'RTO Name').\")\n",
    "if count_col is None:\n",
    "    raise ValueError(\"Could not find the vehicle count column in 2021.csv (expected something like 'Count').\")\n",
    "if veh_type_col is None:\n",
    "    raise ValueError(\n",
    "        \"Could not find a vehicle-type column in 2021.csv.\\n\"\n",
    "        \"To filter out tractors/bicycles and keep 2W/4W, the file must have a type/class/category column.\"\n",
    "    )\n",
    "\n",
    "print(\"Detected columns:\")\n",
    "print(\"  rto_id_col  :\", rto_id_col)\n",
    "print(\"  rto_name_col:\", rto_name_col)\n",
    "print(\"  veh_type_col:\", veh_type_col)\n",
    "print(\"  count_col   :\", count_col)\n",
    "\n",
    "# Create unified RTO label\n",
    "vehicle_raw[\"RTO_LABEL\"] = None\n",
    "if rto_name_col is not None:\n",
    "    vehicle_raw[\"RTO_LABEL\"] = vehicle_raw[rto_name_col].astype(str).str.strip()\n",
    "elif rto_id_col is not None:\n",
    "    vehicle_raw[\"RTO_LABEL\"] = vehicle_raw[rto_id_col].astype(str).str.strip()\n",
    "else:\n",
    "    # both present? prefer name, but keep id as fallback\n",
    "    vehicle_raw[\"RTO_LABEL\"] = (vehicle_raw[rto_id_col].astype(str).str.strip() + \" - \" +\n",
    "                                vehicle_raw[rto_name_col].astype(str).str.strip())\n",
    "\n",
    "# ---- Filter vehicle types: KEEP 2W + 4W, EXCLUDE tractors/bicycles/etc. ----\n",
    "vehicle_raw[\"veh_type_norm\"] = vehicle_raw[veh_type_col].astype(str).str.upper().str.strip()\n",
    "\n",
    "# Keep keywords (tune if your file uses different naming)\n",
    "KEEP_PATTERNS = [\n",
    "    \"TWO WHEELER\", \"2W\", \"MOTORCYCLE\", \"SCOOTER\", \"MOPED\",\n",
    "    \"MOTOR CAR\", \"CAR\", \"JEEP\", \"VAN\", \"FOUR WHEELER\", \"4W\",\n",
    "    \"LMV\"  # sometimes used for light motor vehicle\n",
    "]\n",
    "DROP_PATTERNS = [\n",
    "    \"TRACTOR\", \"BICYCLE\", \"CYCLE\", \"TRAILER\", \"HANDCART\", \"BULLOCK\",\n",
    "    \"CART\", \"ANIMAL\", \"HARVEST\", \"THRESH\", \"FORKLIFT\",\n",
    "    \"CONSTRUCTION\", \"EXCAVATOR\", \"CRANE\"\n",
    "]\n",
    "\n",
    "keep_mask = vehicle_raw[\"veh_type_norm\"].apply(lambda s: any(k in s for k in KEEP_PATTERNS))\n",
    "drop_mask = vehicle_raw[\"veh_type_norm\"].apply(lambda s: any(k in s for k in DROP_PATTERNS))\n",
    "\n",
    "vehicle_filt = vehicle_raw[keep_mask & ~drop_mask].copy()\n",
    "vehicle_filt[count_col] = pd.to_numeric(vehicle_filt[count_col], errors=\"coerce\")\n",
    "vehicle_filt = vehicle_filt.dropna(subset=[count_col])\n",
    "\n",
    "print(f\"✓ Retained {len(vehicle_filt):,} rows after vehicle-type filtering\")\n",
    "print(\"  Sample kept vehicle types:\", vehicle_filt[\"veh_type_norm\"].value_counts().head(8).index.tolist())\n",
    "\n",
    "# ---- Aggregate to RTO-level ownership score ----\n",
    "# Here \"ownership_score\" is total (2W+4W) registrations per RTO (sum across retained types).\n",
    "rto_ownership = (\n",
    "    vehicle_filt.groupby(\"RTO_LABEL\", as_index=False)[count_col]\n",
    "    .sum()\n",
    "    .rename(columns={count_col: \"vehicle_ownership_rto\"})\n",
    ")\n",
    "\n",
    "print(f\"✓ Computed ownership score for {len(rto_ownership)} unique RTO offices\")\n",
    "display(rto_ownership.sort_values(\"vehicle_ownership_rto\", ascending=False).head(10))\n",
    "\n",
    "# ---- RTO office locations ----\n",
    "# IMPORTANT: We will assign EACH WARD to the NEAREST RTO office by distance (metric CRS),\n",
    "# and then use that RTO's ownership score for the ward.\n",
    "rto_locations = pd.DataFrame({\n",
    "    'RTO': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    'RTO_LABEL': ['MALL ROAD', 'IP DEPOT', 'SARAI KALE KHAN', 'JANAKPURI',\n",
    "                  'LONI ROAD', 'MAYUR VIHAR', 'WAZIRPUR', 'DWARKA',\n",
    "                  'RAJA GARDEN', 'ROHINI', 'VASANT VIHAR', 'SURAJMAL VIHAR',\n",
    "                  'HARI NAGAR', 'EAST', 'SOUTH', 'NORTH', 'WEST',\n",
    "                  'CENTRAL', 'NEW DELHI', 'SHAHDARA'],\n",
    "    'lat': [28.7041, 28.6510, 28.5535, 28.6219, 28.7383, 28.6084, 28.7199,\n",
    "            28.5921, 28.6503, 28.7199, 28.5494, 28.6509, 28.6215, 28.6510,\n",
    "            28.5535, 28.7041, 28.6503, 28.6431, 28.6139, 28.6843],\n",
    "    'lon': [77.1025, 77.2526, 77.2577, 77.0807, 77.3184, 77.3051, 77.1674,\n",
    "            77.0460, 77.1272, 77.0674, 77.2001, 77.3389, 77.0524, 77.2526,\n",
    "            77.2577, 77.1025, 77.1272, 77.2197, 77.2090, 77.2749]\n",
    "})\n",
    "print(f\"✓ Using {len(rto_locations)} RTO office locations (fixed list)\")\n",
    "\n",
    "# ---- Match RTO ownership table to location table ----\n",
    "# Vehicle file may use slightly different RTO names than the fixed list.\n",
    "# We'll fuzzy match.\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def fuzzy_match_name(name, choices, cutoff=0.6):\n",
    "    matches = get_close_matches(str(name).upper(), [c.upper() for c in choices], n=1, cutoff=cutoff)\n",
    "    if matches:\n",
    "        # return original choice (preserve exact capitalization from choices)\n",
    "        m_upper = matches[0]\n",
    "        for c in choices:\n",
    "            if c.upper() == m_upper:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "choices = rto_locations[\"RTO_LABEL\"].tolist()\n",
    "rto_ownership[\"RTO_LABEL_MATCHED\"] = rto_ownership[\"RTO_LABEL\"].apply(lambda x: fuzzy_match_name(x, choices, cutoff=0.6))\n",
    "matched_share = rto_ownership[\"RTO_LABEL_MATCHED\"].notna().mean()\n",
    "print(f\"✓ Fuzzy-matched {matched_share*100:.1f}% of RTO labels to the location list\")\n",
    "\n",
    "rto_ref = (\n",
    "    rto_ownership.dropna(subset=[\"RTO_LABEL_MATCHED\"])\n",
    "    .merge(rto_locations, left_on=\"RTO_LABEL_MATCHED\", right_on=\"RTO_LABEL\", how=\"inner\")\n",
    ")\n",
    "\n",
    "if len(rto_ref) == 0:\n",
    "    raise ValueError(\n",
    "        \"No RTO offices matched between vehicle data and rto_locations list.\\n\"\n",
    "        \"You likely need to update rto_locations['RTO_LABEL'] to match your 2021.csv naming.\"\n",
    "    )\n",
    "\n",
    "# ---- Create RTO GeoDataFrame ----\n",
    "rto_gdf = gpd.GeoDataFrame(\n",
    "    rto_ref,\n",
    "    geometry=[Point(xy) for xy in zip(rto_ref[\"lon\"], rto_ref[\"lat\"])],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# ---- Compute ward centroids and assign nearest RTO (metric CRS) ----\n",
    "# Use a projected CRS for accurate distance (meters): EPSG:32643 works for Delhi region.\n",
    "wards_utm = wards.to_crs(\"EPSG:32643\").copy()\n",
    "wards_utm[\"centroid\"] = wards_utm.geometry.centroid\n",
    "wards_cent = wards_utm.set_geometry(\"centroid\")\n",
    "\n",
    "rto_utm = rto_gdf.to_crs(\"EPSG:32643\").copy()\n",
    "\n",
    "# Efficient nearest-neighbor join (GeoPandas >= 0.10 supports sjoin_nearest)\n",
    "try:\n",
    "    ward_to_rto = gpd.sjoin_nearest(\n",
    "        wards_cent[[\"ward_key\", \"centroid\"]],\n",
    "        rto_utm[[\"RTO_LABEL_MATCHED\", \"vehicle_ownership_rto\", \"geometry\"]],\n",
    "        how=\"left\",\n",
    "        distance_col=\"dist_to_rto_m\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    # Fallback if sjoin_nearest isn't available\n",
    "    print(\"⚠️  sjoin_nearest not available, using manual nearest computation. Reason:\", e)\n",
    "    ward_to_rto = wards_cent[[\"ward_key\", \"centroid\"]].copy()\n",
    "    ward_to_rto[\"RTO_LABEL_MATCHED\"] = None\n",
    "    ward_to_rto[\"vehicle_ownership_rto\"] = np.nan\n",
    "    ward_to_rto[\"dist_to_rto_m\"] = np.nan\n",
    "\n",
    "    # brute force (OK for ~290 wards and ~20 RTOs)\n",
    "    for i, w in ward_to_rto.iterrows():\n",
    "        dists = rto_utm.geometry.distance(w[\"centroid\"])\n",
    "        j = int(dists.argmin())\n",
    "        ward_to_rto.at[i, \"RTO_LABEL_MATCHED\"] = rto_utm.iloc[j][\"RTO_LABEL_MATCHED\"]\n",
    "        ward_to_rto.at[i, \"vehicle_ownership_rto\"] = rto_utm.iloc[j][\"vehicle_ownership_rto\"]\n",
    "        ward_to_rto.at[i, \"dist_to_rto_m\"] = float(dists.iloc[j])\n",
    "\n",
    "# Keep only is needed\n",
    "vehicle_per_ward = ward_to_rto[[\"ward_key\", \"vehicle_ownership_rto\", \"dist_to_rto_m\", \"RTO_LABEL_MATCHED\"]].copy()\n",
    "vehicle_per_ward = vehicle_per_ward.rename(columns={\n",
    "    \"vehicle_ownership_rto\": \"vehicle_ownership\",\n",
    "    \"RTO_LABEL_MATCHED\": \"nearest_rto\"\n",
    "})\n",
    "\n",
    "print(f\"✓ Assigned nearest RTO ownership to {vehicle_per_ward['vehicle_ownership'].notna().sum()} wards (should be all wards)\")\n",
    "display(vehicle_per_ward.head())\n",
    "\n",
    "# ---------- NIGHTTIME LIGHTS DATA ----------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6. PROCESSING NIGHTTIME LIGHTS (VIIRS 2012)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    import rasterio\n",
    "    from rasterio.mask import mask\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore', category=rasterio.errors.NotGeoreferencedWarning)\n",
    "    \n",
    "    ntl_file = base_dir / \"raw/VNL_v21_npp_201204-201212_global_vcmcfg_c202205302300.average.dat.tif\" \n",
    "    \n",
    "    # Load the raster data\n",
    "    with rasterio.open(ntl_file) as src:\n",
    "        ntl_crs = src.crs\n",
    "        print(f\"  Raster CRS: {ntl_crs}\")\n",
    "        print(f\"  Raster shape: {src.shape}\")\n",
    "        print(f\"  Raster bounds: {src.bounds}\")\n",
    "        \n",
    "        # Reproject wards to match raster CRS if needed\n",
    "        wards_ntl = wards.to_crs(ntl_crs) if wards.crs != ntl_crs else wards.copy()\n",
    "        \n",
    "        # Extract nighttime lights statistics for each ward\n",
    "        ntl_stats = []\n",
    "        \n",
    "        print(f\"Extracting nighttime lights for {len(wards_ntl)} wards...\")\n",
    "        for idx, ward in wards_ntl.iterrows():\n",
    "            try:\n",
    "                # Mask raster to ward boundary\n",
    "                ward_geom = [ward.geometry.__geo_interface__]\n",
    "                out_image, out_transform = mask(src, ward_geom, crop=True, nodata=0)\n",
    "                \n",
    "                # Extract radiance values (note: values are already multiplied by 1E9)\n",
    "                # Units: nanoWatts/cm²/sr\n",
    "                radiance_values = out_image[0]\n",
    "                \n",
    "                # Filter out zero/nodata values\n",
    "                valid_values = radiance_values[radiance_values > 0]\n",
    "                \n",
    "                if len(valid_values) > 0:\n",
    "                    # Calculate statistics\n",
    "                    mean_radiance = float(valid_values.mean())\n",
    "                    median_radiance = float(np.median(valid_values))\n",
    "                    total_radiance = float(valid_values.sum())\n",
    "                    max_radiance = float(valid_values.max())\n",
    "                    lit_pixels = int(len(valid_values))\n",
    "                else:\n",
    "                    mean_radiance = 0.0\n",
    "                    median_radiance = 0.0\n",
    "                    total_radiance = 0.0\n",
    "                    max_radiance = 0.0\n",
    "                    lit_pixels = 0\n",
    "                \n",
    "                ntl_stats.append({\n",
    "                    'ward_key': ward['ward_key'],\n",
    "                    'nighttime_lights': mean_radiance,  # Primary metric\n",
    "                    'ntl_median': median_radiance,\n",
    "                    'ntl_total': total_radiance,\n",
    "                    'ntl_max': max_radiance,\n",
    "                    'ntl_lit_pixels': lit_pixels\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠️  Error processing ward {ward['ward_key']}: {e}\")\n",
    "                ntl_stats.append({\n",
    "                    'ward_key': ward['ward_key'],\n",
    "                    'nighttime_lights': np.nan,\n",
    "                    'ntl_median': np.nan,\n",
    "                    'ntl_total': np.nan,\n",
    "                    'ntl_max': np.nan,\n",
    "                    'ntl_lit_pixels': 0\n",
    "                })\n",
    "        \n",
    "        ntl_df = pd.DataFrame(ntl_stats)\n",
    "        \n",
    "        print(f\"✓ Nighttime lights extracted for {len(ntl_df)} wards\")\n",
    "        print(f\"  Coverage: {(ntl_df['nighttime_lights'] > 0).sum()} wards with detected lights\")\n",
    "        print(f\"  Mean radiance: {ntl_df['nighttime_lights'].mean():.2f} nW/cm²/sr\")\n",
    "        print(f\"  Median radiance: {ntl_df['nighttime_lights'].median():.2f} nW/cm²/sr\")\n",
    "        print(f\"  Max radiance: {ntl_df['nighttime_lights'].max():.2f} nW/cm²/sr\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⚠️  rasterio not installed. Installing required package...\")\n",
    "    print(\"Run: pip install rasterio\")\n",
    "    # Create empty dataframe with NaN values\n",
    "    ntl_df = pd.DataFrame({\n",
    "        'ward_key': wards['ward_key'],\n",
    "        'nighttime_lights': np.nan,\n",
    "        'ntl_median': np.nan,\n",
    "        'ntl_total': np.nan,\n",
    "        'ntl_max': np.nan,\n",
    "        'ntl_lit_pixels': 0\n",
    "    })\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"⚠️  {e}\")\n",
    "    # Create empty dataframe with NaN values\n",
    "    ntl_df = pd.DataFrame({\n",
    "        'ward_key': wards['ward_key'],\n",
    "        'nighttime_lights': np.nan,\n",
    "        'ntl_median': np.nan,\n",
    "        'ntl_total': np.nan,\n",
    "        'ntl_max': np.nan,\n",
    "        'ntl_lit_pixels': 0\n",
    "    })\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Error processing nighttime lights: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    # Create empty dataframe with NaN values\n",
    "    ntl_df = pd.DataFrame({\n",
    "        'ward_key': wards['ward_key'],\n",
    "        'nighttime_lights': np.nan,\n",
    "        'ntl_median': np.nan,\n",
    "        'ntl_total': np.nan,\n",
    "        'ntl_max': np.nan,\n",
    "        'ntl_lit_pixels': 0\n",
    "    })\n",
    "\n",
    "# ---------- INFRASTRUCTURE METRICS ----------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"7. CALCULATING INFRASTRUCTURE METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Metro stations (expanded list)\n",
    "metro_stations = pd.DataFrame({\n",
    "    'name': ['AIIMS', 'Adarsh Nagar', 'Akshardham', 'Anand Vihar ISBT', 'Arjan Garh', 'Arthala', 'Ashok Park Main', 'Ashram', 'Azadpur', 'Badarpur Border', 'Bahadurgarh City', 'Barakhambha Road', 'Bata Chowk', 'Bhikaji Cama Place', 'Botanical Garden', 'Brigadier Hoshiyar Singh', 'Central Secretariat', 'Chandni Chowk', 'Chawri Bazar', 'Chhatarpur', 'Chirag Delhi', 'Civil Lines', 'Dabri Mor-Janakpuri South', 'Dashrath Puri', 'Delhi Aerocity', 'Delhi Cantonment', 'Delhi Gate', 'Dhaula Kuan', 'Dilshad Garden', 'Durgabai Deshmukh South Campus', 'Dwarka', 'Dwarka Mor', 'Dwarka Sector 10', 'Dwarka Sector 11', 'Dwarka Sector 12', 'Dwarka Sector 13', 'Dwarka Sector 14', 'Dwarka Sector 21', 'Dwarka Sector 8', 'Dwarka Sector 9', 'ESI Hospital', 'East Azad Nagar', 'East Vinod Nagar – Mayur Vihar-II', 'Escorts Mujesar', 'GTB Nagar', 'Ghevra', 'Ghitorni', 'Gokulpuri', 'Golf Course', 'Govind Puri', 'Greater Kailash', 'Green Park', 'Guru Dronacharya', 'HUDA City Centre', 'Haiderpur', 'Harkesh Nagar Okhla', 'Hauz Khas', 'Hazrat Nizamuddin', 'Hindon', 'IFFCO Chowk', 'INA', 'IP Extension', 'ITO', 'Inderlok', 'Indira Gandhi International Airport', 'Indraprastha', 'Jaffrabad', 'Jahangirpuri', 'Jama Masjid', 'Jamia Millia Islamia', 'Janakpuri East', 'Janakpuri West', 'Jangpura', 'Janpath', 'Jasola Apollo', 'Jasola Vihar Shaheen Bagh', 'Jawaharlal Nehru Stadium', 'Jhandewalan', 'Jhilmil', 'Jor Bagh', 'Kailash Colony', 'Kalindi Kunj', 'Kalkaji Mandir', 'Kanhaiya Nagar', 'Karkarduma', 'Karkarduma Court', 'Karol Bagh', 'Kashmere Gate', 'Kaushambi', 'Keshav Puram', 'Khan Market', 'Kirti Nagar†', 'Kohat Enclave', 'Krishna Nagar', 'Lajpat Nagar', 'Lal Qila', 'Laxmi Nagar', 'Lok Kalyan Marg', 'MG Road', 'Madipur', 'Majlis Park', 'Major Mohit Sharma', 'Malviya Nagar', 'Mandawali – West Vinod Nagar', 'Mandi House', 'Mansarovar Park', 'Maujpur-Babarpur', 'Mayapuri', 'Mayur Vihar -I', 'Mayur Vihar Extension', 'Mayur Vihar Pocket I', 'Mewala Maharajpur', 'Model Town', 'Mohan Estate', 'Mohan Nagar', 'Moolchand', 'Moti Nagar', 'Mundka', 'Mundka Industrial Area', 'Munirka', 'Najafgarh', 'Nangli', 'Nangloi', 'Nangloi Railway station', 'Naraina Vihar', 'Nawada', 'Neelam Chowk Ajronda', 'Nehru Enclave', 'Nehru Place', 'Netaji Subhash Place', 'New Ashok Nagar', 'New Delhi', 'Nirman Vihar', 'Noida Electronic City', 'Noida Sector 15', 'Noida Sector 16', 'Noida Sector 18', 'Noida Sector 34', 'Noida Sector 52', 'Noida Sector 59', 'Noida Sector 61', 'Noida Sector 62', 'Okhla Bird Sanctuary', 'Okhla NSIC', 'Okhla Vihar', 'Old Faridabad', 'Palam', 'Panchsheel Park', 'Pandit Shree Ram Sharma', 'Paschim Vihar East', 'Paschim Vihar West', 'Patel Chowk', 'Patel Nagar', 'Peera Garhi', 'Pitam Pura', 'Pratap Nagar', 'Preet Vihar', 'Pul Bangash', 'Punjabi Bagh', 'Punjabi Bagh West', 'R.K.Puram', 'Raj Bagh', 'Raja Nahar Singh', 'Rajdhani Park', 'Rajendra Place', 'Rajiv Chowk', 'Rajouri Garden', 'Ramakrishna Ashram Marg', 'Ramesh Nagar', 'Rithala', 'Rohini East', 'Rohini Sector 18', 'Rohini West', 'Sadar Bazaar Cantonment', 'Saket', 'Samaypur Badli', 'Sant Surdas (Sihi)', 'Sarai', 'Sarita Vihar', 'Sarojini Nagar', 'Satguru Ramsingh Marg', 'Sector 28', 'Seelampur', 'Shadipur', 'Shahdara', 'Shaheed Nagar', 'Shaheed Sthal', 'Shakurpur', 'Shalimar Bagh', 'Shankar Vihar', 'Shastri Nagar', 'Shastri Park', 'Shiv Vihar', 'Shivaji Park', 'Shivaji Stadium', 'Shyam Park', 'Sikandarpur', 'Sir Vishweshwaraiah Moti Bagh', 'South', 'Subhash Nagar', 'Sukhdev Vihar', 'Sultanpur', 'Supreme Court', 'Tagore Garden', 'Tikri Border', 'Tikri Kalan', 'Tilak Nagar', 'Tis Hazari', 'Trilokpuri Sanjay Lake', 'Tughlakabad Station', 'Udyog Bhawan', 'Udyog Nagar', 'Uttam Nagar East', 'Uttam Nagar West', 'Vaishali', 'Vasant Vihar', 'Vidhan Sabha', 'Vinobapuri', 'Vishwa Vidyalaya', 'Welcome', 'Yamuna Bank'],\n",
    "    'lat': [28.56686, 28.714401, 28.617842, 28.646753, 28.480735, 28.676999, 28.671604, 28.572423, 28.707657, 28.4905, 28.690785, 28.629768, 28.385836, 28.5679, 28.563896, 28.69746, 28.615879, 28.660504, 28.65016, 28.506724, 28.538141, 28.676851, 28.615756, 28.601875, 28.548798, 28.593833, 28.639204, 28.59189, 28.675886, 28.589438, 28.577192, 28.61931, 28.581058, 28.586447, 28.592236, 28.597009, 28.602253, 28.551838, 28.565611, 28.574272, 28.658074, 28.664696, 28.620044, 28.370234, 28.698132, 28.685238, 28.493751, 28.702475, 28.597781, 28.544377, 28.541878, 28.558582, 28.482021, 28.459343, 28.730121, 28.543125, 28.544256, 28.588749, 28.878965, 28.472328, 28.574408, 28.628899, 28.630509, 28.651718, 28.554897, 28.620602, 28.682682, 28.725972, 28.65001, 28.55849, 28.633021, 28.62895, 28.582457, 28.60886, 28.538425, 28.545828, 28.583377, 28.644319, 28.675703, 28.588239, 28.553052, 28.545219, 28.549775, 28.680064, 28.649162, 28.6536, 28.644187, 28.651718, 28.645329, 28.688926, 28.600135, 28.653281, 28.698042, 28.657846, 28.570602, 17.920862, 28.630555, 28.598385, 28.479458, 28.676475, 28.724431, 28.677611, 28.53392, 28.624971, 28.625556, 28.675739, 28.691978, 28.63718, 28.603133, 28.594158, 28.605862, 28.441875, 28.702714, 28.51959, 28.606319, 28.564404, 28.657859, 28.682434, 28.683449, 28.554886, 28.612304, 28.6173, 28.682401, 28.682201, 28.627338, 28.620276, 28.397482, 28.546058, 28.549257, 28.696052, 28.589088, 28.643642, 28.636506, 28.579354, 28.480863, 28.480863, 28.480863, 28.480863, 28.480863, 28.480863, 28.480863, 28.480863, 28.552942, 28.554483, 28.5613, 28.480863, 28.591893, 28.543352, 28.689281, 28.677398, 28.678651, 28.622966, 28.645586, 28.679807, 28.703268, 28.66649, 28.641495, 28.666375, 28.668945, 28.67032, 28.551426, 28.64086, 28.340019, 28.682308, 28.642496, 28.63278, 28.642152, 28.639244, 28.652744, 28.720806, 28.70759, 28.738348, 28.714957, 28.577151, 28.524411, 28.744616, 28.354651, 28.651718, 28.52866, 28.574158, 28.661933, 28.545257, 28.66983, 28.651636, 28.673404, 28.53078, 28.670611, 28.685767, 28.717453, 28.557439, 28.669975, 28.668278, 28.617538, 28.675032, 28.631509, 28.698807, 28.48127, 28.578533, 28.651718, 28.641807, 28.559748, 28.461658, 28.622288, 28.643764, 28.688025, 28.686866, 28.636548, 28.667132, 28.613453, 28.50236, 28.61053, 28.681103, 28.624846, 28.621757, 28.644091, 28.560691, 28.686322, 28.566976, 28.695037, 28.651718, 28.623278],\n",
    "    'lon': [77.207806, 77.167288, 77.279488, 77.318004, 77.125762, 77.391892, 77.155291, 77.258598, 77.175547, 77.304038, 76.935485, 77.225005, 77.313462, 77.187016, 77.334332, 76.919203, 77.212282, 77.22978, 77.229501, 77.175002, 77.228069, 77.22503, 77.085178, 77.082356, 77.120809, 77.134979, 77.240782, 77.161703, 77.32144, 77.169082, 77.044294, 77.033279, 77.0575, 77.049438, 77.040732, 77.033541, 77.025957, 77.058649, 77.067037, 77.065332, 77.127268, 77.284881, 77.305407, 77.31492, 77.206411, 76.996159, 77.149187, 77.286125, 77.159817, 77.264266, 77.238455, 77.206718, 77.102268, 77.072657, 77.149403, 77.275562, 77.206707, 77.257249, 77.415483, 77.072422, 77.210241, 77.310198, 77.241436, 77.221939, 77.084675, 77.249551, 77.274806, 77.162658, 77.237676, 77.281165, 77.086757, 77.077924, 77.2415, 77.218165, 77.283038, 77.296658, 77.23354, 77.199916, 77.312505, 77.216528, 77.242969, 77.305989, 77.260667, 77.164844, 77.306208, 77.295788, 77.189132, 77.221939, 77.324348, 77.161683, 77.226491, 77.141773, 77.140539, 77.290185, 77.23653, 77.528502, 77.277633, 77.202996, 77.080465, 77.11936, 77.181964, 77.358143, 77.212447, 77.304491, 77.234195, 77.300102, 77.279624, 77.129733, 77.292589, 77.294589, 77.298702, 77.3023, 77.193991, 77.294585, 77.106082, 77.234278, 77.142429, 77.030574, 77.017133, 77.171084, 76.982391, 77.010438, 77.064732, 77.056246, 77.140318, 77.045079, 77.31236, 77.251506, 77.252952, 77.15264, 77.301508, 77.221737, 77.286835, 77.293303, 77.084888, 77.084888, 77.084888, 77.084888, 77.084888, 77.084888, 77.084888, 77.084888, 77.321595, 77.264849, 77.29193, 77.084888, 77.082824, 77.214076, 76.951199, 77.112295, 77.102226, 77.214031, 77.168698, 77.092679, 77.13225, 77.199336, 77.295374, 77.207529, 77.132461, 77.142088, 77.184701, 77.2095, 77.316428, 77.043944, 77.178276, 77.2197, 77.11606, 77.208579, 77.13165, 77.107181, 77.126039, 77.139832, 77.115385, 77.111153, 77.213725, 77.138265, 77.316226, 77.221939, 77.288397, 77.19537, 77.157477, 77.032576, 77.266754, 77.158295, 77.28974, 77.212057, 77.415582, 77.149609, 77.150867, 77.139665, 77.182, 77.250399, 77.03543, 77.130472, 77.216059, 77.268464, 77.092999, 77.175741, 77.221939, 77.108761, 77.2749, 76.870085, 77.239434, 77.112845, 76.964083, 76.977207, 77.096496, 77.216628, 77.308855, 77.29924, 77.213108, 77.080849, 77.065286, 77.055712, 77.068386, 77.160791, 77.221727, 77.249191, 77.214719, 77.221939, 77.267924],\n",
    "})\n",
    "\n",
    "metro_gdf = gpd.GeoDataFrame(\n",
    "    metro_stations,\n",
    "    geometry=[Point(xy) for xy in zip(metro_stations['lon'], metro_stations['lat'])],\n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "# Calculate minimum distance to metro (in km)\n",
    "ward_centroids = wards.to_crs('EPSG:32643').copy()\n",
    "ward_centroids['centroid'] = ward_centroids.geometry.centroid\n",
    "ward_centroids = ward_centroids.set_geometry('centroid')\n",
    "\n",
    "metro_utm = metro_gdf.to_crs('EPSG:32643')\n",
    "\n",
    "metro_access = []\n",
    "for idx, ward in ward_centroids.iterrows():\n",
    "    distances = metro_utm.geometry.distance(ward.geometry) / 1000  # Convert to km\n",
    "    min_distance_km = distances.min()\n",
    "    metro_access.append({\n",
    "        'ward_key': ward['ward_key'],\n",
    "        'metro_access_km': min_distance_km\n",
    "    })\n",
    "\n",
    "metro_access_df = pd.DataFrame(metro_access)\n",
    "print(f\"✓ Metro access calculated for {len(metro_access_df)} wards\")\n",
    "print(f\"  Mean distance: {metro_access_df['metro_access_km'].mean():.2f} km\")\n",
    "\n",
    "# Road density\n",
    "try:\n",
    "    import osmnx as ox\n",
    "    print(\"Downloading road network from OpenStreetMap...\")\n",
    "\n",
    "    roads = ox.graph_from_place('Delhi, India', network_type='drive')\n",
    "    roads_gdf = ox.graph_to_gdfs(roads, nodes=False)\n",
    "    roads_gdf = roads_gdf.to_crs('EPSG:32643')\n",
    "\n",
    "    wards_utm = wards.to_crs('EPSG:32643')\n",
    "    road_density = []\n",
    "\n",
    "    for idx, ward in wards_utm.iterrows():\n",
    "        ward_roads = roads_gdf[roads_gdf.intersects(ward.geometry)]\n",
    "        total_length = ward_roads.geometry.length.sum() / 1000\n",
    "        density = total_length / ward['ward_area_km2'] if ward['ward_area_km2'] > 0 else 0\n",
    "        road_density.append({\n",
    "            'ward_key': ward['ward_key'],\n",
    "            'road_density_km_per_km2': density\n",
    "        })\n",
    "\n",
    "    road_density_df = pd.DataFrame(road_density)\n",
    "    print(f\"✓ Road density calculated for {len(road_density_df)} wards\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Could not calculate road density: {e}\")\n",
    "    road_density_df = pd.DataFrame({\n",
    "        'ward_key': wards['ward_key'],\n",
    "        'road_density_km_per_km2': np.nan\n",
    "    })\n",
    "\n",
    "# ---------- DISTRICT FIXED EFFECTS ----------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"8. CREATING DISTRICT FIXED EFFECTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "district_dummies = pd.get_dummies(wards['district'], prefix='district')\n",
    "district_dummies['ward_key'] = wards['ward_key'].values\n",
    "print(f\"✓ Created {len(district_dummies.columns)-1} district dummy variables\")\n",
    "\n",
    "# ======================================================================\n",
    "# -------------------------- FINAL MERGE (REWRITTEN) --------------------\n",
    "# ======================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"9. MERGING ALL DATA SOURCES — WITH NEAREST-RTO VEHICLE OWNERSHIP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "final_df = wards[['ward_key', 'ward_id', 'ward_name', 'district', 'ward_area_km2']].copy()\n",
    "\n",
    "final_df = final_df.merge(ward_metrics, on='ward_key', how='left')\n",
    "final_df = final_df.merge(ward_pop[['ward_key', 'Population', 'population_density']], on='ward_key', how='left')\n",
    "final_df = final_df.merge(vehicle_per_ward, on='ward_key', how='left')\n",
    "final_df = final_df.merge(ntl_df, on='ward_key', how='left')\n",
    "final_df = final_df.merge(metro_access_df, on='ward_key', how='left')\n",
    "final_df = final_df.merge(road_density_df, on='ward_key', how='left')\n",
    "final_df = final_df.merge(district_dummies, on='ward_key', how='left')\n",
    "\n",
    "print(f\" Final dataset: {len(final_df)} rows × {len(final_df.columns)} columns\")\n",
    "print(f\"  Vehicle ownership coverage: {(final_df['vehicle_ownership'].notna().mean()*100):.1f}%\")\n",
    "print(f\"  (Optional) Nearest RTO label coverage: {(final_df['nearest_rto'].notna().mean()*100):.1f}%\")\n",
    "\n",
    "\n",
    "# ---------- DATA QUALITY CHECKS ----------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"10. DATA QUALITY CHECKS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing = final_df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "if len(missing) > 0:\n",
    "    print(f\"Missing value summary:\")\n",
    "    print(missing.head(10))\n",
    "else:\n",
    "    print(\"✓ No missing values!\")\n",
    "\n",
    "checks = {\n",
    "    'Ward keys unique': len(final_df['ward_key'].unique()) == len(final_df),\n",
    "    'Bus service coverage': f\"{(final_df['BusServiceIntensity'].notna().sum() / len(final_df) * 100):.1f}%\",\n",
    "    'Population coverage': f\"{(final_df['Population'].notna().sum() / len(final_df) * 100):.1f}%\",\n",
    "    'Vehicle ownership coverage': f\"{(final_df['vehicle_ownership'].notna().sum() / len(final_df) * 100):.1f}%\",\n",
    "    'Nighttime lights coverage': f\"{(final_df['nighttime_lights'].notna().sum() / len(final_df) * 100):.1f}%\",\n",
    "    'Metro access coverage': f\"{(final_df['metro_access_km'].notna().sum() / len(final_df) * 100):.1f}%\"\n",
    "}\n",
    "\n",
    "for check, value in checks.items():\n",
    "    print(f\"  {check}: {value}\")\n",
    "\n",
    "# ---------- SAVE OUTPUT ----------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"11. SAVING OUTPUT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Dataset saved: {output_file}\")\n",
    "print(f\"\\nFinal shape: {final_df.shape}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "numeric_cols = ['BusServiceIntensity', 'Population', 'vehicle_ownership',\n",
    "                'nighttime_lights', 'metro_access_km', 'population_density']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in final_df.columns and final_df[col].notna().sum() > 0:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Mean: {final_df[col].mean():.2f}\")\n",
    "        print(f\"  Std: {final_df[col].std():.2f}\")\n",
    "        print(f\"  Min: {final_df[col].min():.2f}\")\n",
    "        print(f\"  Max: {final_df[col].max():.2f}\")\n",
    "        print(f\"  Missing: {final_df[col].isna().sum()} ({(final_df[col].isna().sum()/len(final_df)*100):.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ ANALYSIS COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(final_df[['ward_key', 'ward_name', 'Population', 'vehicle_ownership',\n",
    "                'nighttime_lights', 'BusServiceIntensity']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
